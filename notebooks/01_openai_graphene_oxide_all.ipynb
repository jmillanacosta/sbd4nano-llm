{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install -qU huggingface_hub\n",
    "%pip install nest-asyncio\n",
    "%pip install unstructured\n",
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Necessary to import OpenAI\n",
    "with open('assets/openai_api_key', 'r') as f:\n",
    "    openai_api_key = f.read()\n",
    "with open('assets/huggingface_api_key', 'r') as f:\n",
    "    huggingface_api_key = f.read()\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "os.environ['HUGGINGFACEHUB_API_KEY'] = huggingface_api_key\n",
    "from pathlib import Path\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain.chains import RetrievalQA\n",
    "import ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI QA\n",
    "\n",
    "We use Langchain to create a Chroma database of our papers against which we will query our questions. The answers are provided in the requested structure, making it straightforward to extract information.\n",
    "\n",
    "Every paper is evaluated separately.\n",
    "\n",
    "TODO: improve documentation\n",
    "\n",
    "https://python.langchain.com/docs/modules/chains/additional/question_answering.html\n",
    "\n",
    "https://python.langchain.com/docs/modules/chains/additional/openai_functions_retrieval_qa\n",
    "\n",
    "\n",
    "Setting up the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "paper_path = '../data/docs/'\n",
    "pickle_path = '../data/pickle/'\n",
    "chroma_path = '../data/chroma/'\n",
    "MODEL = 'gpt-3.5-turbo'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the vector database:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the prompt template:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"We are trying to extract information from a journal article that focuses on bioassays performed on graphene oxide to investigate its effects on and interactions with biological systems and organisms. Our objective is to extract details about the assays conducted and how different measurement groups and conditions contribute to various effects.\n",
    "\n",
    "Please use the provided journal article as context to fill out the keys in the format defined below. Ensure that the answer to each key is a comma-separated list. Each element in a given key's list should correspond with the respective elements in other keys, maintaining the same length for all lists. Leaving blanks or having lists of different lengths is not acceptable. Repeated elements are allowed, as the paper describes different conditions for each assay, different endpoints for each animal model, and so on. Be as exhaustive as you can, and do not forget to give an answer for every list element (you will respond 'not specified' if you can't find an answer).\n",
    "\n",
    "\n",
    "Please return the answer to each key as a comma-separated list in such a way that e.g. element 1 of a given key (e.g., diameter measurement units) corresponds with element 1 from a different key (e.g. diameter measurement values) and element 1 from another key (Interaction). This means that it is crucial that all lists must be of the same length -an answer with lists of different lenghts is not acceptable. Each position in the lists represents an individual set of assay conditions, measurements and outcomes, which means that there can be several instances of the same outcome, materials, measurements and conditions.\n",
    "\n",
    "Format:\n",
    "---------\n",
    "question i: [list i of length N]\n",
    "question j: [list j of length N]\n",
    "---------\n",
    "\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "---------\n",
    "Questions: \n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Observed interaction or effect\",\n",
    "             \"Sample preparation\"\n",
    "             \"Bioassays\", \n",
    "             \"Doses\", \n",
    "             \"Doses units\", \n",
    "             \"Coatings\", \n",
    "             \"Organisms/Biological systems\", \n",
    "             \"Shapes\", \n",
    "             \"Diameters measurement units\", \n",
    "             \"Diameters measurement values\",\n",
    "             \"Diameters measurement types\",\n",
    "             \"Time point values\",\n",
    "             \"Time point units\", \n",
    "             \"Passages\"]\n",
    "\n",
    "query = \"\"\"\n",
    "    Observed interaction or effect: [List of observed outcomes]\n",
    "    Sample preparation technique: [List of sample preparation techniques]\n",
    "    Bioassays: [List of specific bioassays performed]\n",
    "    Doses: [List of graphene oxide doses]\n",
    "    Doses units: [List of units for graphene oxide doses]\n",
    "    Coatings: [List of nanomaterial coating types reported]\n",
    "    Organisms/Biological systems: [List of organisms or biological systems used in  the assay]\n",
    "    Shapes: [List of graphene oxide shapes that produced the outcomes]\n",
    "    Diameters measurement units: [List of units for diameter measurements]\n",
    "    Diameters measurement values: [List of numeric values for diameter  measurements]\n",
    "    Diameters measurement types: [List of types of diameter measurements]\n",
    "    Time point values: [List of time points at which effects were observed]\n",
    "    Time point units: [List of units for time points]\n",
    "    Passages: [List of literal excerpts from the text asserting the outcomes]\n",
    "\n",
    "\"\"\"\n",
    "regex = \"(.*)\\n\".join(questions) + '\\n(.*)'\n",
    "\n",
    "\n",
    "output_parser = RegexParser(\n",
    "    regex=regex,\n",
    "    output_keys=questions,\n",
    ")\n",
    "\n",
    "doc_prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['context', 'question'],\n",
    "    output_parser=output_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def papers_to_vectors(paper_path):\n",
    "    #TODO be able to restore persistent chroma\n",
    "    loader = DirectoryLoader(paper_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = Chroma.from_documents(texts, embeddings,persist_directory=f'../data/chroma/{paper_path}', metadatas=[{\"source\": str(i)} for i in range(len(texts))])\n",
    "    docsearch.persist()\n",
    "    return docsearch\n",
    "#documents = os.listdir(paper_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, runs, query, doc_prompt):\n",
    "    docsearch = papers_to_vectors(path)\n",
    "    res = {str(i): {} for i in range(runs)}\n",
    "    for i in range(runs):\n",
    "        print(f'Run #{i} ...')\n",
    "        chain_type_kwargs = {'prompt': doc_prompt}\n",
    "        qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"map_rerank\", retriever=docsearch.as_retriever(), chain_type_kwargs=chain_type_kwargs, return_source_documents=True)\n",
    "        result = qa({'query': query})\n",
    "        rows = result['result'].split(\"\\n\")\n",
    "        \n",
    "        for row in rows:\n",
    "            if 'Answer' not in row and ':' in row:\n",
    "                row_name, values = row.split(\":\", 1)\n",
    "                values = values.split(\",\")\n",
    "                res[str(i)][row_name] = values\n",
    "        res[str(i)]['source_documents'] = result['source_documents']\n",
    "    res['query'] = result['query']\n",
    "    return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/docs/test/'\n",
    "runs = 10\n",
    "query = query\n",
    "test_am3 = get_data(path, runs, query, doc_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_am3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def occurrence_interactions(results, runs):\n",
    "    seen_interactions = {}\n",
    "    for iteration in results.keys():\n",
    "        if type(results[iteration]) == dict:\n",
    "            values = results[iteration]:\n",
    "            interaction = values['Observed interaction or effect']:\n",
    "            if interaction not in seen_interactions.keys():\n",
    "                seen_interactions[interaction] = {'vals':{}, 'count': 1}\n",
    "            \n",
    "            else:\n",
    "                seen_interactions[interaction]['count'] += 1\n",
    "            for other_keys in values.keys():\n",
    "                \n",
    "    occurences = {i: {'vals': seen_interactions[i]['vals'], 'freq': seen_interactions[i]['count']/runs} for i in seen_interactions.keys()}\n",
    "    return occurences\n",
    "seen = occurrence_interactions(test_am3, runs)\n",
    "seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_am3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = result['result'].split(\"\\n\")\n",
    "new_table = []\n",
    "row_names = []\n",
    "for row in rows:\n",
    "    if ':' in row:\n",
    "        row_name = row.split(\":\")[0]\n",
    "        values = row.split(\":\")[1]\n",
    "        row_names.append(row_name)\n",
    "        values = values.split(\",\")\n",
    "        new_table.append(values)\n",
    "df = pd.DataFrame(new_table, index = row_names).drop('Answer')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
